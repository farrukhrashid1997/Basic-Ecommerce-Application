{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR-10_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMpegkHIIRZWSrt/ffspCAM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farrukhrashid1997/Basic-Ecommerce-Application/blob/master/CIFAR_10_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgb8X4Aq_PWo",
        "colab_type": "code",
        "outputId": "972593ab-7c49-44c8-ccc5-236b87b02f20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras import backend as K\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMKdgKf8_syj",
        "colab_type": "code",
        "outputId": "7e0ae231-64cd-49a6-bd78-c89bf065c277",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#loading the cifar10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 13s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTpjFceLCIFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Creating the configuration of the VGG model\n",
        "#The main point here is that 3x3 filters are used since they will act as 5x5 filters, reducing the no of hyperparameters.\n",
        "#This way we can introduce more non-linearity preventing overfitting.\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:] , activation='relu'))\n",
        "model.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding = 'same', activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), padding = 'same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(1, 1)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(1, 1)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXGSLXn7E3Ka",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#I have used an imagedatagenerator, this basically iterates over the training data and flips some of them horizontally, changes the zoom range.\n",
        "#This is done usually to make the model better, prevent it from overfitting.\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    dtype = 'float32',\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "#This generator is used as a validation generator or test generator\n",
        "test_datagen = ImageDataGenerator(rescale=1./255, \n",
        "                                  dtype = 'float32')\n",
        "\n",
        "\n",
        "validation_generator = test_datagen.flow(\n",
        "    x_test, y_test, batch_size = 32)\n",
        "\n",
        "\n",
        "\n",
        "train_datagen.fit(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xK0pyl9jGN-5",
        "colab_type": "code",
        "outputId": "3e2c2065-2711-4004-9230-a7c78de37b49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "source": [
        "train_generator = train_datagen.flow(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=100)\n",
        "\n",
        "\n",
        "#Usually more than 80% is achieved if 100 epochs were run. I wanted to try loading ResNet weights and try then. I didnt due to internet problems.\n",
        "model.fit_generator(train_generator,\n",
        "                    epochs = 10,\n",
        "                    validation_data=validation_generator,\n",
        "                    workers = 4\n",
        "                    )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "500/500 [==============================] - 767s 2s/step - loss: 2.0001 - accuracy: 0.2678 - val_loss: 1.3747 - val_accuracy: 0.4320\n",
            "Epoch 2/10\n",
            "500/500 [==============================] - 711s 1s/step - loss: 1.4583 - accuracy: 0.4743 - val_loss: 1.2077 - val_accuracy: 0.5797\n",
            "Epoch 3/10\n",
            "500/500 [==============================] - 710s 1s/step - loss: 1.2094 - accuracy: 0.5710 - val_loss: 1.1106 - val_accuracy: 0.6043\n",
            "Epoch 4/10\n",
            "500/500 [==============================] - 744s 1s/step - loss: 1.0559 - accuracy: 0.6306 - val_loss: 0.7550 - val_accuracy: 0.6807\n",
            "Epoch 5/10\n",
            "500/500 [==============================] - 746s 1s/step - loss: 0.9555 - accuracy: 0.6692 - val_loss: 1.3230 - val_accuracy: 0.6707\n",
            "Epoch 6/10\n",
            "500/500 [==============================] - 755s 2s/step - loss: 0.8864 - accuracy: 0.6952 - val_loss: 1.1106 - val_accuracy: 0.6953\n",
            "Epoch 7/10\n",
            "500/500 [==============================] - 770s 2s/step - loss: 0.8391 - accuracy: 0.7104 - val_loss: 0.8593 - val_accuracy: 0.7253\n",
            "Epoch 8/10\n",
            "500/500 [==============================] - 781s 2s/step - loss: 0.8053 - accuracy: 0.7255 - val_loss: 0.6651 - val_accuracy: 0.7512\n",
            "Epoch 9/10\n",
            "500/500 [==============================] - 784s 2s/step - loss: 0.7822 - accuracy: 0.7347 - val_loss: 0.8903 - val_accuracy: 0.7325\n",
            "Epoch 10/10\n",
            "500/500 [==============================] - 774s 2s/step - loss: 0.7629 - accuracy: 0.7431 - val_loss: 0.3565 - val_accuracy: 0.7337\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f7ac382e668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8-aei8AKS_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#I have also saved the weights, we can recreate the model above and load the weights. \n",
        "model.save_weights('/content/Lab11.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuGrQGqVgbMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = model.evaluate_generator(validation_generator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8K7O7gxhHPS",
        "colab_type": "code",
        "outputId": "51d71a22-86a3-47ba-f1bf-42ac339f778c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(\"The accuracy of the model is \",  acc[1]*100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the model is  73.36999773979187\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evZVXvNEih2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}